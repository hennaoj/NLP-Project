{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bb9511",
   "metadata": {},
   "source": [
    "Task 9 Part 1, where the Reuters corpus is used instead of the BNC. In this part compatibilty is checked using the WordNet Domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b01714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import pickle\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226ec1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_without_tags = list(reuters.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4877f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "\n",
    "for sentence in sents_without_tags:\n",
    "    tagged_words = nltk.pos_tag(sentence)\n",
    "    sents.append(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3cebd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4b7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "special_chars = ['(',')',',','\"','.','!','?','-','\\'','‘','’','—',':']\n",
    "for w in words:\n",
    "    if w not in special_chars and not w.isnumeric():\n",
    "        wordlist.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08483de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455539f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To increase performance, we will calculate all word frequencies here at once\n",
    "#Previously we calculated one at a time, resulting in hundereds of loops over wordlist\n",
    "\n",
    "#Runtime ~15 seconds\n",
    "freqDist = FreqDist(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926eca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pair(sentence):\n",
    "    '''\n",
    "    Finds adjective/adverb-noun part-of-speech in a given sentence using nltk part-of-speech tagging. \n",
    "    Returns only the first occurence of such pair in a sentence.\n",
    "    '''\n",
    "    pair = []\n",
    "    tagged_words = nltk.pos_tag(sentence.split())\n",
    "    adjectives = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']\n",
    "    nouns = ['NN', 'NNS', 'NNPS', 'NNP']\n",
    "    for i in range(len(tagged_words) - 1):\n",
    "        word1_category = tagged_words[i][1]\n",
    "        word2_category = tagged_words[i + 1][1]\n",
    "        if word1_category in adjectives and word2_category in nouns:\n",
    "            pair = [tagged_words[i][0].lower(), re.sub('\\W+','', tagged_words[i + 1][0]).lower()]\n",
    "            return pair\n",
    "    return pair\n",
    "\n",
    "def find_pairs(sentence):\n",
    "    '''\n",
    "    Finds adjective/adverb-noun part-of-speech in a given sentence using nltk part-of-speech tagging. \n",
    "    Returns all occurences of such pairs in a sentence.\n",
    "    '''\n",
    "    pairs = []\n",
    "    tagged_words = nltk.pos_tag(sentence.split())\n",
    "    adjectives = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']\n",
    "    nouns = ['NN', 'NNS', 'NNPS', 'NNP']\n",
    "    for i in range(len(tagged_words) - 1):\n",
    "        word1_category = tagged_words[i][1]\n",
    "        word2_category = tagged_words[i + 1][1]\n",
    "        if word1_category in adjectives and word2_category in nouns:\n",
    "            pairs.append([tagged_words[i][0].lower(), re.sub('\\W+','', tagged_words[i + 1][0]).lower()])\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def check_senses(pair):\n",
    "    '''\n",
    "    Given an adjective/adverb-noun pair checks that the adjective/adverb has more than one sense and the noun has an\n",
    "    entry in WordNet.\n",
    "    '''\n",
    "    adj = pair[0]\n",
    "    noun = pair[1]\n",
    "    if len(wn.synsets(adj)) == 1:\n",
    "        print('Adjective has only one sense!')\n",
    "        return 2\n",
    "    elif len(wn.synsets(noun)) == 0:\n",
    "        print('Noun has no entry in WordNet!')\n",
    "        return 3\n",
    "    return True\n",
    "\n",
    "def find_words_near(node):\n",
    "    '''\n",
    "    Finds nouns appearing next to a given node word by checking each sentence of the corpus individually.\n",
    "    '''\n",
    "    #print('Looking for words appearing next to', node)\n",
    "    words_near = []\n",
    "    for sentence in sents:\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i][0] == node:\n",
    "                indexesToTry = [i - 1, i + 1]\n",
    "                for index in indexesToTry:\n",
    "                    if index >= 0 and index < len(sentence):\n",
    "                        if sentence[index][1] and sentence[index][1] in ('NN', 'NNS', 'NNPS', 'NNP', 'SUBST'):\n",
    "                            words_near.append(sentence[index][0].lower())\n",
    "    return words_near\n",
    "\n",
    "def find_collocates(node, words_near):\n",
    "    '''\n",
    "    Finds all unique collocate nouns from a list of nouns that appear near the node word. A noun is considered a collocate\n",
    "    when its mutual information to the node is greater or equal to 3. Only considers nouns that appear at least twice\n",
    "    near the node word.\n",
    "    '''\n",
    "    #print('Determining the collocates of', node)\n",
    "    collocates = []\n",
    "    checked = []\n",
    "    #freq_node = wordlist.count(node) #Replaced by taking frequency from precalculated distribution\n",
    "    freq_node = freqDist[node]\n",
    "    if freq_node > 0:\n",
    "        for word in words_near:\n",
    "            if word not in checked:\n",
    "                checked.append(word)\n",
    "                freq_near = words_near.count(word)\n",
    "                if freq_near >= 2:\n",
    "                    #freq_collocate = wordlist.count(word) #Replaced by taking frequency from precalculated distribution\n",
    "                    freq_collocate = freqDist[word]\n",
    "                    if freq_collocate > 0:\n",
    "                        mutual_information = calculate_mutual_information(freq_node, freq_collocate, freq_near)\n",
    "                        if mutual_information >= 3:\n",
    "                            if (word, mutual_information) not in collocates:\n",
    "                                collocates.append((word, mutual_information))\n",
    "    return collocates\n",
    "\n",
    "def calculate_mutual_information(freq_node, freq_collocate, freq_near):\n",
    "    '''\n",
    "    Calculates the mutual information between a node and a possible collocate using the expression (2) in\n",
    "    the article https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0062343 by Neuman et al (2013).\n",
    "    '''\n",
    "    corpus_size = len(wordlist)\n",
    "    span = 2 #maybe?\n",
    "    mutual_information = np.log10((freq_near * corpus_size)/(freq_node * freq_collocate * span))/np.log10(2)\n",
    "    return mutual_information\n",
    "\n",
    "with open('WordNet2/Words.cat', 'r') as file:\n",
    "    data = file.readlines()\n",
    "    nouns = data[25040:94946]\n",
    "    \n",
    "tidy_nouns = []\n",
    "for noun in nouns:\n",
    "    noun = noun.replace(' (1)', '')\n",
    "    noun = noun.replace('\\t', '')\n",
    "    noun = noun.replace('\\n', '')\n",
    "    noun = noun.lower()\n",
    "    tidy_nouns.append(noun)\n",
    "\n",
    "def find_classes(collocates):\n",
    "    '''\n",
    "    Classifies a list of nouns using WordStat. Returns a list of nouns (and their mutual information also given in\n",
    "    the input list) that belong to a concrete class. The list is sorted by the mutual information value in ascending order.\n",
    "    '''\n",
    "    Lem = WordNetLemmatizer()\n",
    "\n",
    "    current_class = ''\n",
    "    classified_nouns = []\n",
    "    \n",
    "    #there should be 13 concrete classes out of the 25 classes\n",
    "    concrete_classes = ['animal', 'artifact', 'body', 'event', 'food', 'group', 'location', 'object', 'person', 'possession',\n",
    "                       'plant', 'shape', 'substance']\n",
    "\n",
    "    for target in collocates:\n",
    "        if tidy_nouns.count(target[0]) > 0:\n",
    "            for noun in tidy_nouns:\n",
    "                #changing the noun class (e.g. when noun.food is encountered, class is 'food' until the next noun\n",
    "                #class is encountered)\n",
    "                if 'noun.' in noun:\n",
    "                    noun_split = noun.split('.')\n",
    "                    current_class = noun_split[1]\n",
    "                elif noun == target[0] and current_class in concrete_classes:\n",
    "                    #only adding nouns that are not already in the list (some might be in more than one conrete class)\n",
    "                    if (noun, target[1]) not in classified_nouns:\n",
    "                        classified_nouns.append((noun, target[1]))\n",
    "    #sorting by the mutual information value\n",
    "    classified_nouns = sorted(classified_nouns, key=itemgetter(1))\n",
    "    return classified_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "971aa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the WordNet domain categorising uses version 2.0 (or 1.6) of WordNet and the current nltk version is 3.0,\n",
    "#we need to download WordNet version 2 and use the noun.data file in the dict folder to get the correct offset ids for synsets.\n",
    "\n",
    "with open('WordNet2.0/dict/noun.dat', 'r') as file:\n",
    "    wn_data = file.readlines()[29:79719]\n",
    "\n",
    "def find_offsets(node):\n",
    "    '''\n",
    "    Returns all possible WordNet offset ids for a given noun.\n",
    "    '''\n",
    "    offsets = []\n",
    "    for line in wn_data:\n",
    "        line = line.split()\n",
    "        offset = line[0]\n",
    "        pos = line[2]\n",
    "        word = line[4]\n",
    "        if word == node:\n",
    "            offsets.append(offset)\n",
    "    return offsets\n",
    "\n",
    "#Domains can be downloaded from https://wndomains.fbk.eu/download.html\n",
    "\n",
    "\n",
    "with open('Domains/domains_2', 'r') as file: #domains_2 = wn-domains-3.2-20070223\n",
    "    domain_data = file.readlines()\n",
    "\n",
    "def find_domains(target_offset):\n",
    "    '''\n",
    "    Returns the domains matching a given WordNet offset id.\n",
    "    '''\n",
    "    found_domains = []\n",
    "    for line in domain_data:\n",
    "        line = line.split('-')\n",
    "        offset = line[0].lstrip(\"0\")\n",
    "        domains = line[1][2:-1]\n",
    "        if offset == target_offset:\n",
    "            domains = domains.split(' ')\n",
    "            for domain in domains:\n",
    "                found_domains.append(domain)\n",
    "    return found_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc7c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_metaphor(sentence):\n",
    "    '''\n",
    "    Determines whether a sentence includes a type III metaphor (adjective/adverb-noun metaphor) by going through a set of steps.\n",
    "    '''\n",
    "    pair = find_pair(sentence)\n",
    "    if not pair:\n",
    "        print('No pair!')\n",
    "        return 3\n",
    "    #print('Pair found: ', pair)\n",
    "        \n",
    "    adjective = pair[0]\n",
    "    noun = pair[1]\n",
    "    \n",
    "    check = check_senses(pair)\n",
    "    if check == 2:\n",
    "        #print(adjective, noun, 'is not a metaphore')\n",
    "        return 0\n",
    "    elif check == 3:\n",
    "        return 3\n",
    "    \n",
    "    words_near = find_words_near(adjective)\n",
    "    \n",
    "    collocates = find_collocates(adjective, words_near)\n",
    "    #print('Found', len(collocates), 'unique collocates')\n",
    "    \n",
    "    if not collocates:\n",
    "        print('No collocates found')\n",
    "        return 3\n",
    "\n",
    "    classified_nouns = find_classes(collocates)\n",
    "    #print(len(classified_nouns), 'collocate words appear in concrete classes')\n",
    "    \n",
    "    if not classified_nouns:\n",
    "        #print(adjective, noun, 'is a metaphore')\n",
    "        return 1\n",
    "    \n",
    "    top_three = classified_nouns[-3:]\n",
    "    #print('The top three collocates are', top_three)\n",
    "    \n",
    "    node_domains = []\n",
    "    node_offsets = find_offsets(noun)\n",
    "    for offset in node_offsets:\n",
    "        node_domains.append(find_domains(offset.lstrip(\"0\")))\n",
    "        \n",
    "    node_domains = [domain for sublist in node_domains for domain in sublist]\n",
    "    \n",
    "    collocate_domains = []\n",
    "    for collocate in top_three:\n",
    "        offsets = find_offsets(collocate[0])\n",
    "        for offset in offsets:\n",
    "            collocate_domains.append(find_domains(offset.lstrip(\"0\")))\n",
    "            \n",
    "    for domain in node_domains:\n",
    "        if any(domain in sublist for sublist in collocate_domains):\n",
    "            #print('At least one of the top three collocates and the node noun belong to the domain', domain)\n",
    "            #print(adjective, noun, 'is not a metaphore')\n",
    "            return 0\n",
    "        \n",
    "    #print(adjective, noun, 'is a metaphore')\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef3516b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_metaphor_deep(sentence):\n",
    "    '''\n",
    "    Determines whether a sentence includes a type III metaphor (adjective/adverb-noun metaphor) by going through a set of steps.\n",
    "    '''\n",
    "    pairs = find_pairs(sentence)\n",
    "    if not pairs:\n",
    "        print('No pairs!')\n",
    "        return 3\n",
    "    #print('Pairs found: ', pairs)\n",
    "    tempReturn = []\n",
    "    for pair in pairs:\n",
    "        \n",
    "        adjective = pair[0]\n",
    "        noun = pair[1]\n",
    "        \n",
    "        check = check_senses(pair)\n",
    "        if check == 2:\n",
    "            #print(adjective, noun, 'is not a metaphore')\n",
    "            tempReturn.append(0)\n",
    "            continue\n",
    "        elif check == 3:\n",
    "            tempReturn.append(3)\n",
    "            continue\n",
    "        \n",
    "        words_near = find_words_near(adjective)\n",
    "        \n",
    "        collocates = find_collocates(adjective, words_near)\n",
    "        #print('Found', len(collocates), 'unique collocates')\n",
    "        \n",
    "        if not collocates:\n",
    "            print('No collocates found')\n",
    "            tempReturn.append(3)\n",
    "            continue\n",
    "\n",
    "        classified_nouns = find_classes(collocates)\n",
    "        #print(len(classified_nouns), 'collocate words appear in concrete classes')\n",
    "        \n",
    "        if not classified_nouns:\n",
    "            #print(adjective, noun, 'is a metaphore')\n",
    "            tempReturn.append(1)\n",
    "            continue\n",
    "        \n",
    "        top_three = classified_nouns[-3:]\n",
    "        #print('The top three collocates are', top_three)\n",
    "        \n",
    "        node_domains = []\n",
    "        node_offsets = find_offsets(noun)\n",
    "        for offset in node_offsets:\n",
    "            node_domains.append(find_domains(offset.lstrip(\"0\")))\n",
    "            \n",
    "        node_domains = [domain for sublist in node_domains for domain in sublist]\n",
    "        \n",
    "        collocate_domains = []\n",
    "        for collocate in top_three:\n",
    "            offsets = find_offsets(collocate[0])\n",
    "            for offset in offsets:\n",
    "                collocate_domains.append(find_domains(offset.lstrip(\"0\")))\n",
    "                \n",
    "        for domain in node_domains:\n",
    "            if any(domain in sublist for sublist in collocate_domains):\n",
    "                #print('At least one of the top three collocates and the node noun belong to the domain', domain)\n",
    "                #print(adjective, noun, 'is not a metaphore')\n",
    "                tempReturn.append(0)\n",
    "                continue\n",
    "            \n",
    "        #print(adjective, noun, 'is a metaphore')\n",
    "        tempReturn.append(1)\n",
    "    if 1 in tempReturn:\n",
    "        return 1\n",
    "    elif 0 in tempReturn:\n",
    "        return 0\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635768a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset is quite problematic because the text is so unclean:\\n(\\nthe night is each man \\'s castle . @2@y\\nswelling lukewarm ; her mouth is water , @5@y\\n& yet the earth is divinity , the sky is divinity @4@n\\n\"i am the resurrection and the life . \" @1@n\\n\"how is the dean ? \" -- \"he \\'s just alive . \" @1@n <-- especially problematic, because quotation mark is connected to the word\\n)\\nIf all special characters are cleaned a way, the head word\\nposition tag may change, and we cannot reliably verify the algorithm.\\nIf not cleaned, the some words are left unrecognized...\\n\\nFor now, data is not cleaned before taking it to the algorithm\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Formatting of the metaphor annotated corpus: http://aclweb.org/anthology/W/W17/W17-2201.pdf\n",
    "Example: destroying alexandria . sunlight is silence @4@y\n",
    "@-sign separates different fields\n",
    "Sentece:                        destroying alexandria . sunlight is silence\n",
    "Position of the head word       4 -> sunlight\n",
    "Is the expression a metaphore?  y ()\n",
    "'''\n",
    "annotatedSentences = []\n",
    "headWordPosition = []\n",
    "isSentenceMetaphor = []\n",
    "with open(\"type1_metaphor_annotated.txt\") as textfile:\n",
    "    for line in textfile: \n",
    "        line = line.split(\"@\")\n",
    "        if(line[2].strip() != 's'): #Exclude sentences which humans failed to classify\n",
    "            annotatedSentences.append(line[0].strip())\n",
    "            headWordPosition.append(line[1].strip())\n",
    "            isSentenceMetaphor.append(line[2].strip())\n",
    "\n",
    "'''\n",
    "The dataset is quite problematic because the text is so unclean:\n",
    "(\n",
    "the night is each man 's castle . @2@y\n",
    "swelling lukewarm ; her mouth is water , @5@y\n",
    "& yet the earth is divinity , the sky is divinity @4@n\n",
    "\"i am the resurrection and the life . \" @1@n\n",
    "\"how is the dean ? \" -- \"he 's just alive . \" @1@n <-- especially problematic, because quotation mark is connected to the word\n",
    ")\n",
    "If all special characters are cleaned a way, the head word\n",
    "position tag may change, and we cannot reliably verify the algorithm.\n",
    "If not cleaned, the some words are left unrecognized...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8746055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earth is the birth of the blues   sang yellow bertha\n",
      "\"earth is the birth of the blues , \" sang yellow bertha ,\n"
     ]
    }
   ],
   "source": [
    "#We'll do some simple cleaning\n",
    "cleanAnnotatedSentences = [re.sub(r'[^a-zA-Z ]', '', sent) for sent in annotatedSentences]\n",
    "cleanAnnotatedSentences[:] = [s.strip() for s in cleanAnnotatedSentences]\n",
    "\n",
    "print(cleanAnnotatedSentences[13])\n",
    "print(annotatedSentences[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eef8d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Noun has no entry in WordNet!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "Adjective has only one sense!\n",
      "No collocates found\n",
      "Adjective has only one sense!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No collocates found\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n",
      "No pair!\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for sentence in cleanAnnotatedSentences:\n",
    "    result = is_a_metaphor(sentence)\n",
    "    if result == 3:\n",
    "        predictions.append('u')\n",
    "    elif result == 1:\n",
    "        predictions.append('y')\n",
    "    else:\n",
    "        predictions.append('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a7017a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n",
      "487\n",
      "680\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "print(predictions.count('u'))\n",
    "print(len(isSentenceMetaphor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68ef1420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 53\n",
      "Negatives: 47\n",
      "Predicted positives: 57\n",
      "Predicted negatives: 43\n",
      "TP: 30\n",
      "FP: 27\n",
      "TN: 20\n",
      "FN: 23\n"
     ]
    }
   ],
   "source": [
    "PredictedPositives = predictions.count('y')\n",
    "PredictedNegatives = predictions.count('n')\n",
    "TruePositives = 0\n",
    "FalsePositives = 0\n",
    "TrueNegatives = 0\n",
    "FalseNegatives = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 'y' and isSentenceMetaphor[i] == 's':\n",
    "        PredictedPositives -=1\n",
    "    elif predictions[i] == 'n' and isSentenceMetaphor[i] == 's':\n",
    "        PredictedNegatives -=1\n",
    "    elif predictions[i] == 'u':\n",
    "        continue\n",
    "    elif predictions[i] == 'y' and isSentenceMetaphor[i] == 'y':\n",
    "        TruePositives +=1\n",
    "    elif predictions[i] == 'y' and isSentenceMetaphor[i] == 'n':\n",
    "        FalsePositives += 1\n",
    "    elif predictions[i] == 'n' and isSentenceMetaphor[i] == 'n':\n",
    "        TrueNegatives += 1\n",
    "    elif predictions[i] == 'n' and isSentenceMetaphor[i] == 'y':\n",
    "        FalseNegatives += 1\n",
    "        \n",
    "Positives = TruePositives + FalseNegatives #Ground truth\n",
    "Negatives = TrueNegatives + FalsePositives #Ground truth\n",
    "\n",
    "print(\"Positives: \" + str(Positives))\n",
    "print(\"Negatives: \" + str(Negatives))\n",
    "print(\"Predicted positives: \" + str(PredictedPositives))\n",
    "print(\"Predicted negatives: \" + str(PredictedNegatives))\n",
    "print(\"TP: \" + str(TruePositives))\n",
    "print(\"FP: \" + str(FalsePositives))\n",
    "print(\"TN: \" + str(TrueNegatives))\n",
    "print(\"FN: \" + str(FalseNegatives))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b59cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TruePositives + TrueNegatives) / (Positives + Negatives)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bb9c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "precision = TruePositives / (TruePositives + FalsePositives)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d710e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5660377358490566\n"
     ]
    }
   ],
   "source": [
    "recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af612432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "43b9575b074e1392a1c24d545d7a593cce1ed78c3ebf689988faf70d4f44ec55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
